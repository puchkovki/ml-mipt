{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Day_3_CNN_for_texts.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework01: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02 seminar](https://github.com/girafe-ai/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfCvkEXl0bA3"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFm57rSn0bA3",
        "outputId": "d29f3686-b76e-441a-a7fd-000d34659645"
      },
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  119M  100  119M    0     0  47.4M      0  0:00:02  0:00:02 --:--:--  137M\n",
            "Train_rev1.csv\n",
            "--2021-03-17 15:35:23--  https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py’\n",
            "\n",
            "network.py          100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-17 15:35:23 (37.9 MB/s) - ‘network.py’ saved [1469/1469]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWkpd7PycOQ",
        "outputId": "308083a8-f027-4cf0-ff4a-86fd17338ea2"
      },
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "911it [00:00, 9101.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "239768it [00:30, 7799.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wxTypqi0bA7",
        "outputId": "2b3bfb2d-d5c9-48f2-cd59-73bcd0ca7702"
      },
      "source": [
        "token_counts.most_common(1)[0][1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "bc6f1384-f5cf-4a00-c56a-c8066c5c8b70"
      },
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "36307e30-5485-4886-8191-1ff8dfa071d5"
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "276def3d-37af-44a0-bf1f-d9ea722701db"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "4b101134-5def-42e6-9cc2-c4b3bb613863"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WIs5Is0bBD"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUgp4XA0bBD"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHRDQV-t0bBE"
      },
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5lLA_040bBE"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTIGjIH0bBF"
      },
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGsQbXwn0bBG"
      },
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cWqricc0bBG"
      },
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xniqr5vc0bBH",
        "outputId": "4d0959e1-be31-43fe-c4a9-877fffc45a8b"
      },
      "source": [
        "batch"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'FullDescription': array([[  927,  4938, 15922, ...,     1,     1,     1],\n",
              "        [16658, 30725,   891, ...,     1,     1,     1],\n",
              "        [    0, 14825, 25792, ..., 31523,   195,  5342]], dtype=int32),\n",
              " 'Title': array([[15649,  8992,     1,     1,     1,     1,     1],\n",
              "        [22330,  8894, 10702,     0, 24343, 27169,  6347],\n",
              "        [25355, 21211,    32,  1522,    63,  8430,     1]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B7Y7JEH0bBI"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnKDDg9z0bBJ",
        "outputId": "4f447a0c-d3f3-483e-b6b2-086351bc7ada"
      },
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2481],\n",
              "        [0.3384],\n",
              "        [0.1497]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lAynI4a0bBK",
        "outputId": "faab9b1e-831f-4ee9-8140-c8e8c0ca3abe"
      },
      "source": [
        "batch['FullDescription'].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 410)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arEOwQkb0bBK"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbOxa7D3gUU"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9fw4sqpK0bBL",
        "outputId": "21f32652-d949-4b01-b600-1d9a38e96ec9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = simple_model\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
        "\n",
        "        target = torch.tensor(target).to(device)\n",
        "\n",
        "\n",
        "        predictions = model(batch).to(device)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRypT33z0bBL"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0tfbJn0bBM"
      },
      "source": [
        "import network"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAq9zhrt0bBM",
        "outputId": "8170a05f-eb3a-43e0-bb02-466a112708aa"
      },
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLoOWpz_0bBM"
      },
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features=100 \n",
        ")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUG7J8IE0bBM"
      },
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC_bf8wz0bBN",
        "outputId": "d2cc0e2d-4f5b-45d5-f6a8-d8ad29229640"
      },
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems fine!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPjA6id-0bBN"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f55e5gB40bBN",
        "outputId": "48daeeb9-9f56-4150-aba6-9052c3b83d88"
      },
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch1 = torch.tensor(batch['Title'], dtype=torch.long).to(device)\n",
        "        batch2 = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        batch3 = torch.tensor(batch['Categorical']).to(device)\n",
        "        \n",
        "        target = torch.tensor(target).to(device)\n",
        "        \n",
        "        whole_input = [batch1, batch2, batch3]\n",
        "\n",
        "\n",
        "        predictions = model(whole_input)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlP1nBQt0bBN"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zi3mVEX0bBO",
        "outputId": "d032508d-b9d0-4b96-da7b-471ecc9a694d"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_proc): Sequential(\n",
              "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_proc): Sequential(\n",
              "    (0): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (category_out): Sequential(\n",
              "    (0): Linear(in_features=3746, out_features=3746, bias=True)\n",
              "    (1): Linear(in_features=3746, out_features=3746, bias=True)\n",
              "  )\n",
              "  (post_concat): Linear(in_features=3938, out_features=100, bias=True)\n",
              "  (inter_dense): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jti8g_s0bBO"
      },
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xDjgWLw7voj"
      },
      "source": [
        "model = model.to(torch.device('cpu'))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86Jl8gc90bBP",
        "outputId": "97ec0a99-a068-4a85-e9b6-7de73b794252"
      },
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20it [00:13,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.20301\n",
            "Mean absolute error: 0.35331\n",
            "Submission file generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIVGfP5x0bBP"
      },
      "source": [
        "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
      ]
    }
  ]
}