{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment1_02_three_headed_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework01: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02 seminar](https://github.com/girafe-ai/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfCvkEXl0bA3"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFm57rSn0bA3",
        "outputId": "c9d98bfb-dbff-4029-868b-bbf529e16b78"
      },
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   145    0   145    0     0    788      0 --:--:-- --:--:-- --:--:--   783\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  119M  100  119M    0     0  64.4M      0  0:00:01  0:00:01 --:--:--  158M\n",
            "Train_rev1.csv\n",
            "--2021-03-19 09:59:15--  https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py.2’\n",
            "\n",
            "network.py.2        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-19 09:59:15 (31.5 MB/s) - ‘network.py.2’ saved [1469/1469]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg-FVv_b6onb"
      },
      "source": [
        "# run this cell if you have already downloaded the dataset\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWkpd7PycOQ",
        "outputId": "4f0e6759-b1c9-4a7a-89e5-84831275d959"
      },
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "842it [00:00, 8417.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "239768it [00:30, 7860.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wxTypqi0bA7",
        "outputId": "a79dad1c-2e0d-4743-d5fb-2c97b9fb2640"
      },
      "source": [
        "token_counts.most_common(1)[0][1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "8b6fa176-3a98-4c40-893c-98570af24b80"
      },
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "30daa8e0-3bf7-47d6-d9fa-21088ff4f3af"
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "e2dce589-f079-4c59-91cb-7e1cf039d771"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "8be97120-d12d-4fa7-f912-dba18506036c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WIs5Is0bBD"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUgp4XA0bBD"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHRDQV-t0bBE"
      },
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5lLA_040bBE"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTIGjIH0bBF"
      },
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGsQbXwn0bBG"
      },
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cWqricc0bBG"
      },
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xniqr5vc0bBH",
        "outputId": "4ce32cc0-5da6-4623-c45f-8e1ec5827261"
      },
      "source": [
        "batch"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'FullDescription': array([[13360,  5847, 15353, ...,     1,     1,     1],\n",
              "        [26688, 20603,   195, ...,   195,     0,    80],\n",
              "        [30512, 16289,  2120, ...,     1,     1,     1]], dtype=int32),\n",
              " 'Title': array([[13360,  5847, 15353, 18670,     1],\n",
              "        [26688, 20603,   195, 24167, 26688],\n",
              "        [ 4938,  9000, 18670,     1,     1]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B7Y7JEH0bBI"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnKDDg9z0bBJ",
        "outputId": "1352bbf6-23c5-4b1b-ad5d-1d1b185a158c"
      },
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1268],\n",
              "        [-0.0170],\n",
              "        [-0.0148]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lAynI4a0bBK",
        "outputId": "f2d6ffec-d6d0-4e65-923e-1dde1a1f5d3e"
      },
      "source": [
        "batch['FullDescription'].shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 345)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arEOwQkb0bBK"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbOxa7D3gUU"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9fw4sqpK0bBL",
        "outputId": "c2d12bd3-bed4-47ef-8e21-05951ccb9654"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = simple_model\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
        "\n",
        "        target = torch.tensor(target).to(device)\n",
        "\n",
        "\n",
        "        predictions = model(batch).to(device)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRypT33z0bBL"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0tfbJn0bBM"
      },
      "source": [
        "import network"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAq9zhrt0bBM",
        "outputId": "877eb030-6d2c-429a-cab8-d52db8714c1c"
      },
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLoOWpz_0bBM"
      },
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features=100 \n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUG7J8IE0bBM"
      },
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC_bf8wz0bBN",
        "outputId": "436ab8ad-8869-4354-8e0a-a42b1ae40b36"
      },
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems fine!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPjA6id-0bBN"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f55e5gB40bBN",
        "outputId": "714b722f-7a9c-4a50-80ab-35b631266f1a"
      },
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch1 = torch.tensor(batch['Title'], dtype=torch.long).to(device)\n",
        "        batch2 = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        batch3 = torch.tensor(batch['Categorical']).to(device)\n",
        "        \n",
        "        target = torch.tensor(target).to(device)\n",
        "        \n",
        "        whole_input = [batch1, batch2, batch3]\n",
        "\n",
        "\n",
        "        predictions = model(whole_input)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlP1nBQt0bBN"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zi3mVEX0bBO",
        "outputId": "1efa9c75-b3aa-492b-b734-4b574d35eefd"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_proc): Sequential(\n",
              "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_proc): Sequential(\n",
              "    (0): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (category_out): Sequential(\n",
              "    (0): Linear(in_features=3746, out_features=3746, bias=True)\n",
              "    (1): Linear(in_features=3746, out_features=3746, bias=True)\n",
              "  )\n",
              "  (post_concat): Linear(in_features=3938, out_features=100, bias=True)\n",
              "  (inter_dense): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=100, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jti8g_s0bBO"
      },
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xDjgWLw7voj"
      },
      "source": [
        "model = model.to(torch.device('cpu'))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86Jl8gc90bBP",
        "outputId": "b38761ba-4498-4f9b-bca2-5573d295c0d3"
      },
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20it [00:13,  1.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.28415\n",
            "Mean absolute error: 0.42240\n",
            "Submission file generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIVGfP5x0bBP"
      },
      "source": [
        "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
      ]
    }
  ]
}